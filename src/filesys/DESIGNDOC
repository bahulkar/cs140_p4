         +-------------------------+
         |          CS 140         |
         | PROJECT 4: FILE SYSTEMS |
         |     DESIGN DOCUMENT     |
         +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Tejas Bahulkar <tejasbahulkar@gmail.com>
Cory Benavides <corymichael@gmail.com>
Adeline Wong <adelinew@alumni.stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

         INDEXED AND EXTENSIBLE FILES
         ============================

---- DATA STRUCTURES ----

directory.c
-----------
/* A single directory entry. */
struct dir_entry 
  {
    ...
    bool is_file;                       /* Is file or directory */
  };

filesys.c
---------
/* Lock to protect list of file names. */
struct lock cur_name_list_lock;

/* List of file names being created/removed. */
struct list cur_name_list;

/* List entry for list of file names. */
struct cur_name_list_entry
{
  struct list_elem elem; /* Hash table element. */
  char file_name [NAME_MAX + 1];     /* file/directory name. */
  block_sector_t parent_dir_sector; /* inumber of parent dir. */
};

inode.c
-------
/* On-disk inode.
   Must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct inode_disk
  {
    off_t length;                         /* File size in bytes. */
    unsigned magic;                       /* Magic number. */
    block_sector_t index[INDEX_ARRAY_LENGTH]; /* Index array. */
    block_sector_t single_index;          /* Single index. */
    block_sector_t double_index;          /* Double index. */
  };

/* Lock to protect current inode list. */
struct lock cur_inode_list_lock;

/* List of current inodes - used for synchronization. */
struct list cur_inode_list;

/* List element of current inode list. */
struct cur_inode_list_entry
{
  struct list_elem elem;      /* List element. */
  block_sector_t inumber;     /* inumber for the inode. */
  struct condition cond;      /* cond var for synchronization. */
  bool currently_growing;     /* file growth in progress. */
};
  
thread.c
--------
/* Representation of an opened file. */
struct fd_list_elem
  {
    ...
    bool is_file;                       /* If fd represents file or dir.*/
    int inumber;                        /* inumber for file/dir. */
  };

struct thread
  {
    ...
    block_sector_t pwd_sector;          /* Sector where pwd is stored. */
    ...
  };


>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.
Sector size: 512 bytes
Each sector entry needs 4 bytes of storage
Each sector can store (512/4)=128 sector entries.
Inode structure:
1. 4 bytes to store file length
2. 4 bytes to store magic number
2. 124 direct index entries -> can addresses 124 * 512 = 63488 bytes.
3. 1 direct index entry -> can addresses 128 * 512 = 65536 bytes.
3. 1 doubly-indirect index entry -> can addresses 128 * (65536) = 8388608
   bytes.
Total file size supported:
  63488
+ 65536
+ 8388608
= 8517632 bytes > 8MB.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.
There is a global list that has an entry per file created. Each entry
has a condition variable associated with it. This condition variable 
prevents simultaneous file growth on the same file. However, different
files can grow at the same time. There is a lock to protect the list 
access and the condition variable.
The condition wait happens before the file growth starts, and the signal
happens only after the data is written.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.
A file read is blocked till file growth is complete if a file is growing.
This will allow the reader to see either the old or the new, but no
intermediate contents.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.
Blocking is done only while growing a file. At all other times, multiple
accesses are allowed. As file sizes are limited to approx. 8MB, there
will be no forever waiting. This should ensure fairness. 

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?
Yes, our inode structure is a multilevel index.
It has 4 bytes for file length, 125 direct index entries, 1 single index
entry and 1 double index entry.
This design has the following advantages:
1. It makes full use of the inode space.
2. It allows for file growth without fragmentation.
3. It allows accesses of files unto (124 * 512) bytes without any need
for extra indirection.
4. It allows accesses of files up to ((124 * 512) + (128 * 512)) bytes with 
only one extra level of indirection.
5. It allows files to grow up to ((124 * 512) + (128 * 512) + (128 * (128
 * 512))) bytes.

          SUBDIRECTORIES
          ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?
An absolute path starts with '/'
Any other path is relative to the current working directory.
We store the current working directory's inumber in the thread struct.
And the root directory's inumber is fixed.
Also, whenever any directory is created (including root), 2 entries
are added - 
one named '.' which is for the newly created directory.
one named '..' which is for its parent directory.
Thus given any path, we simply tokenize the path using '/' as a 
delimiter and we lookup the token in its parent directory, and hence
can traverse the entire path.

Absolute and relative path traversal differ only in the way that they 
start out with different parent directories (absolute paths have root
as their parent directory, and relative paths have the current working
directory as their parent directory). After that point, the traversal
mechanism is the same as described above.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.
There is synchronization during directory entry creation and removal.
An directory entry can uniquely be identified by its name and the number
of its parent directory. A list global to the filesystem (protected by a 
lock) stores the file/directory name that is currently being added/removed
and its parent's inumber. When a file/directory is to be added/removed, 
it first checks in the list if another file of the same name in the same
directory is being added/removed. If so, then it fails. Otherwise it
adds itself to the list and the the actual creation/removal takes place.
After that, it removes itself from the list.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?
Our implementation does not allow the current working directory to be
removed. A directory is allowed to be removed only if it empty (that is
in our case, it has no entries other than '.' and '..').

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.
We chose to represent the current directory of a process by its number.
This is for 2 reasons:
1. The number for a directory remains the same for the entire lifetime
of the directory.
2. Given an inumber, you can directly access the directory and its
entries without need for any pre-traversal. Every directory has entries 
for '.' and '..' which permit easy relative path traversal starting from
the current working directory.


           BUFFER CACHE
           ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

block-cache.h
-------------
/* Block cache element states */
enum block_cache_mode
  {
    BCM_UNUSED,               /* Never been used. On unused queue. */
    BCM_EVICTED,              /* Was evicted. On unused queue. */
    BCM_ACTIVE,               /* Active cache data.  Active queue */
    BCM_READ,                 /* Needs to be read from disk. Active queue. */
    BCM_READING,              /* Reading from disk. Active queue. */
    BCM_WRITING,              /* Writing to disk. No queue. */
  };

/* Block cache. Block must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct block_cache_elem
  {
    struct hash_elem hash_elem;         /* Hash table element. */
    struct list_elem list_elem;         /* Element in block cache list. */
    struct list_elem clock_elem;        /* Element for the clock algorithm. */
    block_sector_t sector;              /* Sector number of disk location. */
    uint8_t *block;                     /* Block data. */
    bool dirty;                         /* True if dirty. */
    uint8_t accessed;                   /* One for standara accesses,
                                           two for inode accesses */
    bool pinned;                        /* True when locking element
                                           for thread safety. */
    enum block_cache_mode state;        /* Current state: Evicted, etc. */
    unsigned magic;                     /* Magic number. */
  };

-hash_elem is used for fast cache lookups in the block_cache_table
-clock_elem links together all elements with valid mappings (ie, no unused or
evicted elements). The clock algorithm walks this queue in block_cache_evict.
-list_elem places the element on either the active_queue (all elements with
cached data), the unused_queue (no active data), or the read_queue (cache
elements to be read-ahead).

/* Lock to synchronize accesses to cache table. */
struct lock block_cache_lock;

/* Condition when a read completes. */
struct condition cond_read;

/* Condition when a write completes. */
struct condition cond_write;

/* Lock to synchronize accesses to cache table. */
struct lock block_cache_lock;

block-cache.c
-------------
/* Array of all the block_cache_elem's */
static struct block_cache_elem block_cache_elems[MAX_CACHE_SECTORS];

/* Block cache buffer storage. */
static uint8_t block_cache[MAX_CACHE_SECTORS][BLOCK_SECTOR_SIZE];

/* List of cache blocks with no pending operations. */
static struct list block_cache_active_queue;

/* List of empty blocks to be used for caching. */
static struct list block_cache_unused_queue;

/* List of cache blocks waiting to be filled with data from disk. */
static struct list block_cache_read_queue;

/* Block cache table. */
static struct hash block_cache_table;

/* Condition when an element is ready for read-ahead. */
static struct condition cond_read_queue_add;

/* Prevents multiple threads from concurrently evicting. */
static struct lock clock_lock;

/* Clock algorithm hand for eviction*/
static struct list_elem * clock_hand_le;

/* List of cache blocks used for the eviction algorithm. */
static struct list block_cache_clock_elem_queue;

inode.c
-------
/* In-memory inode. */
struct inode 
  {
    ...
    struct inode_disk * data;             /* Inode content. */
    struct block_cache_elem * bce;        /* Holds the cached data content. */
  };

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.
We are using a modified clock algorithm. The buffer cache elements are stored
in the block_cache_clock_elem_queue.  The clock hand traverses the
queue to find the next cache element to evict.  The criteria for eviction is:
1) Not pinned (aka, not actively reading, writing, or evicting data to disk)
2) The access count is 0.
The access count in an integer set to 1 for a data block and 2 for an inode
every time the cache is hit for a read or write.  It is incremented once more
the first time it is set to dirty and on subsequent cache hits. The accessed
count will not be set for read-aheads.  The accessed count will be decremented
once the clock hand passes to the next element.


>> C3: Describe your implementation of write-behind.
If a buffer cache element exists, all writes will be written directly to the
cached buffer in memory.  Upon eviction, the cached block data will be written
to disk and the block & buffer cache element will then be made available for
the next block data to be cached.  For data integrity, dirty blocks and the free map are periodically saved to disk (every 2 seconds on the periodic_write_thread).  As an aside, the free map was modified to be kept in memory until the periodic writes.

>> C4: Describe your implementation of read-ahead.
Whenever a sector is read (which has a one to one mapping to blocks in Pintos)
the sector/block is looked up in the buffer cache. If it doesn't exist, a new
buffer cache element will be provided (upon evicting a stale cache element, if
needed). Subsequently, the next sector is also looked up, and a cache element
is also provided if not found. The read-ahead cache elements are queued on the
block_cache_read_queue. The read-ahead thread will then load the blocks for the
queued cache elements from disk on a low-priority background thread.  If the
block is requested before the read-ahead starts, the block will be removed
from the read-ahead queue and the block_read will be called immediately.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?
When a block is being copied from/to another buffer using buffer_cache_write or
buffer_cache_read the I/O is protected by the same buffer_cache_lock that
protects eviction.

Moreover, whenever the buffer_cache_lock is released during I/O to the block
(from either disk or inode manipulation), the buffer cache element is first
pinned and then the lock is released.  Other processes check the pinned flag
before manipulating the data inside of the buffer cache element.  If they need
access to the element, then the other process waits for a cond_read or
cond_write depending on the type of I/O (one single cond_io would have worked,
but two conditions are used as a slight optimization).  For clarity, the state
of the buffer cache element is also set to BCM_READING or BCM_WRITING during
disk I/O.


>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?
Same as for all I/O.  There is a lock that is hierarchically passed to all
inner-level buffer_cache_x & inode_x functions that use the buffer_cache.  The
lock is held at all times in these functions except for during disk I/O or on
cond_broadcasts.  To protect the element when the lock is released, the buffer
cache element is pinned before the lock is released, and unpinned when the lock
is restored.  The other processes will wait for the eviction to complete and
will cache miss the block when they resume.  The block will then be refetched. 

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.
Buffer caches will benefit any file workload that works repeatedly with the
same blocks.  For instance when navigating a directory structure, the directory
inodes are frequently reaccessed.  Read-ahead will benefit reading sequential
blocks in one larger file (it will work best when the blocks are stored
sequentially on disk).  Examples would include reading large spreadsheets, text
files, images, movies, etc.  Write-behind will benefit workloads that involve
frequently editing the contents of the same block on disk.  Examples include a
user that frequently saves a document being edited, files that store
system/application settings, etc.


         SURVEY QUESTIONS
         ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?